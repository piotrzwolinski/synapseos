#!/usr/bin/env python3
"""
Guardian Test Suite - Tests tricky questions that require domain reasoning.
Uses LLM to evaluate if the system response matches expected behavior.
"""

import requests
import json
from google import genai
from google.genai import types
import os
from dataclasses import dataclass
from typing import Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv(dotenv_path="../.env")

# Initialize Gemini client for evaluation
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
EVAL_MODEL = "gemini-2.0-flash"

API_URL = "http://localhost:8000/consult/deep-explainable"


@dataclass
class TestCase:
    id: int
    name: str
    query: str
    expected_action: str
    reasoning: str


TEST_CASES = [
    TestCase(
        id=1,
        name="Pu≈Çapka Fizyczna (Py≈Ç vs Gaz)",
        query="Mamy problem ze smrodem spalin na parkingu. Dobierz mi obudowƒô workowƒÖ GDB, ≈ºeby to odfiltrowaƒá.",
        expected_action="CRITICAL WARNING + PIVOT DO GDC. System musi odrzuciƒá GDB (filtruje py≈Ç, nie gaz) i wymusiƒá zmianƒô na seriƒô wƒôglowƒÖ GDC.",
        reasoning="Filtr workowy (GDB) zatrzymuje py≈Ç, a nie gaz. System musi u≈ºyƒá First Principles, by odrzuciƒá pro≈õbƒô u≈ºytkownika."
    ),
    TestCase(
        id=2,
        name="Pu≈Çapka Korozyjna (Materia≈Ç)",
        query="Potrzebujƒô taniej obudowy do wentylacji na basenie. Proszƒô o wycenƒô standardowego modelu GDB w ocynku (FZ).",
        expected_action="CRITICAL WARNING + AUTO-UPGRADE DO ZM/RF. System musi zignorowaƒá pro≈õbƒô 'tanio/ocynk' i wymusiƒá materia≈Ç odporny na korozjƒô.",
        reasoning="Basen = Chlor = Korozja. Ocynk (C3) nie wytrzyma. Wymagany ZM (C5) lub RF (nierdzewka)."
    ),
    TestCase(
        id=3,
        name="Pu≈Çapka Termiczna (Kondensacja)",
        query="Szukam obudowy GDB do monta≈ºu na dachu. Bud≈ºet jest napiƒôty, wiƒôc bez izolacji.",
        expected_action="WARNING + REKOMENDACJA GDMI. System musi ostrzec przed kondensacjƒÖ i zarekomendowaƒá izolowanƒÖ seriƒô.",
        reasoning="Dach + Brak izolacji = Kondensacja (woda w filtrach). Oszczƒôdno≈õƒá na izolacji zniszczy filtry."
    ),
    TestCase(
        id=4,
        name="Pu≈Çapka Geometryczna (Opcja w za ma≈Çej obudowie)",
        query="Zamawiam obudowƒô wƒôglowƒÖ GDC o d≈Çugo≈õci 750 mm. Musi mieƒá zamontowanƒÖ szynƒô na polisfiltr (filtr doczyszczajƒÖcy).",
        expected_action="BLOCK / CONFIGURATION ERROR. Opcja 'szyna na polisfiltr' wymaga min. 900 mm d≈Çugo≈õci.",
        reasoning="W 750 mm fizycznie siƒô nie zmie≈õci szyna na polisfiltr. System musi zablokowaƒá konfiguracjƒô."
    ),
    TestCase(
        id=5,
        name="Pu≈Çapka Niejednoznaczno≈õci (Brak Danych)",
        query="Dobierz mi obudowƒô GDB do biurowca. Monta≈º wewnƒÖtrz.",
        expected_action="CLARIFICATION NEEDED. System musi zapytaƒá o wymagany przep≈Çyw/wielko≈õƒá.",
        reasoning="GDB wystƒôpuje w wielu rozmiarach. System nie mo≈ºe zgadnƒÖƒá przep≈Çywu dla 'biurowiec'."
    ),
    TestCase(
        id=6,
        name="Pu≈Çapka Higieniczna (Szpital)",
        query="Projekt: Szpital Wojew√≥dzki. Klient chce przyoszczƒôdziƒá i prosi o obudowy GDB w ocynku. Czy mogƒô to wyceniƒá?",
        expected_action="CRITICAL WARNING (Hygiene Violation). Ocynk niedopuszczalny w szpitalu, wymagana stal nierdzewna (RF).",
        reasoning="Szpital = Wymogi Higieniczne (VDI 6022). Ocynk to ryzyko w strefach czystych."
    ),
    TestCase(
        id=7,
        name="Pu≈Çapka Terminologiczna (Produkt vs Komponent)",
        query="Chcƒô zbudowaƒá ≈õcianƒô filtracyjnƒÖ w murowanym kanale. Potrzebujƒô 20 sztuk obud√≥w GDP-600x600, ale bez blachy, same ramki.",
        expected_action="PIVOT DO PFF. System powinien rozpoznaƒá intencjƒô i zaproponowaƒá PFF zamiast GDP.",
        reasoning="U≈ºytkownik prosi o GDP (szafkƒô), ale opisuje PFF (ramƒô monta≈ºowƒÖ)."
    ),
    TestCase(
        id=8,
        name="Pu≈Çapka Kompatybilno≈õci (Z≈Çe akcesorium)",
        query="Czy do obudowy GDC (Wƒôglowej) mogƒô zam√≥wiƒá mechanizm dociskowy EXL?",
        expected_action="BLOCK / INCOMPATIBLE. EXL jest dla GDB/GDMI, GDC u≈ºywa mocowania bagnetowego.",
        reasoning="Mechanizm EXL dedykowany do filtr√≥w workowych. GDC ma inny system mocowania."
    ),
    TestCase(
        id=9,
        name="Pu≈Çapka Monta≈ºowa (Retrofit 'na styk')",
        query="Mam wnƒôkƒô o d≈Çugo≈õci 800 mm. Czy zmieszczƒô tam GDB-Long (750mm) plus ramkƒô na filtr wstƒôpny (50mm)?",
        expected_action="WARNING (Zero Tolerance). 750 + 50 = 800 teoretycznie pasuje, ale praktycznie brak marginesu.",
        reasoning="Matematyka: 750 + 50 = 800. W praktyce (b≈Çƒôdy monta≈ºowe) to ryzyko."
    ),
    TestCase(
        id=10,
        name="Pu≈Çapka Zastosowania (T≈Çuszcz)",
        query="Potrzebujƒô filtr√≥w wƒôglowych (GDC) do okapu w sma≈ºalni frytek.",
        expected_action="APPLICATION WARNING. Wƒôgiel aktywny zaklei siƒô t≈Çuszczem bez silnej prefiltracji.",
        reasoning="Wƒôgiel aktywny w GDC natychmiast zaklei siƒô t≈Çuszczem. Wymaga prefiltracji (separatory t≈Çuszczu)."
    ),
]


def query_system(query: str) -> dict:
    """Send query to the deep-explainable endpoint."""
    try:
        response = requests.post(
            API_URL,
            json={"query": query},
            timeout=120
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        return {"error": str(e)}


def evaluate_response(test_case: TestCase, system_response: dict) -> dict:
    """Use LLM to evaluate if system response matches expected behavior."""

    eval_prompt = f"""You are evaluating a Product Recommendation System's response.

## TEST CASE: {test_case.name}

### User Query:
{test_case.query}

### Expected System Behavior:
{test_case.expected_action}

### Why This Is Tricky (Expected Reasoning):
{test_case.reasoning}

### Actual System Response:
```json
{json.dumps(system_response, indent=2, ensure_ascii=False)}
```

## EVALUATION TASK:
Analyze the system's response and determine:

1. **DETECTION** (0-10): Did the system detect the trap/risk in the query?
   - 10 = Explicitly identified the exact risk
   - 5 = Partially identified or hinted at the issue
   - 0 = Completely missed the trap

2. **ACTION** (0-10): Did the system take the correct action?
   - 10 = Exactly matched expected action (warning, block, pivot, clarification)
   - 5 = Partially correct (warned but didn't pivot, or weak warning)
   - 0 = Wrong action (proceeded without warning, wrong recommendation)

3. **REASONING** (0-10): Did the system explain the physical/chemical/domain reasoning?
   - 10 = Clear explanation of WHY (first principles physics/chemistry)
   - 5 = Mentioned the issue but weak reasoning
   - 0 = No reasoning provided

4. **OVERALL PASS/FAIL**: Based on above scores

Return JSON:
{{
  "detection_score": <0-10>,
  "detection_analysis": "<what did system detect or miss>",
  "action_score": <0-10>,
  "action_analysis": "<what action did system take vs expected>",
  "reasoning_score": <0-10>,
  "reasoning_analysis": "<quality of system's reasoning>",
  "overall_score": <0-10 average>,
  "pass": <true if overall >= 7>,
  "summary": "<1-2 sentence verdict>"
}}
"""

    try:
        response = client.models.generate_content(
            model=EVAL_MODEL,
            contents=[types.Content(role="user", parts=[types.Part.from_text(text=eval_prompt)])],
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                temperature=0.1,
            ),
        )
        return json.loads(response.text)
    except Exception as e:
        return {"error": str(e), "pass": False, "overall_score": 0}


def run_tests():
    """Run all test cases and print results."""
    print("=" * 80)
    print("üß™ GUARDIAN TEST SUITE - Tricky Questions Evaluation")
    print("=" * 80)

    results = []
    passed = 0
    failed = 0

    for test in TEST_CASES:
        print(f"\n{'‚îÄ' * 80}")
        print(f"üìã Test {test.id}: {test.name}")
        print(f"{'‚îÄ' * 80}")
        print(f"Q: {test.query[:100]}...")
        print(f"Expected: {test.expected_action[:80]}...")
        print()

        # Query the system
        print("‚è≥ Querying system...")
        system_response = query_system(test.query)

        if "error" in system_response:
            print(f"‚ùå API Error: {system_response['error']}")
            results.append({"test_id": test.id, "pass": False, "error": system_response['error']})
            failed += 1
            continue

        # Show key parts of response
        response_type = system_response.get("response_type", "unknown")
        risk_detected = system_response.get("risk_detected", False)
        risk_severity = system_response.get("risk_severity", "none")

        print(f"üì§ Response Type: {response_type}")
        print(f"‚ö†Ô∏è  Risk Detected: {risk_detected} (Severity: {risk_severity})")

        # Show reasoning summary
        reasoning = system_response.get("reasoning_summary", [])
        if reasoning:
            print("üß† Reasoning:")
            for step in reasoning[:3]:
                print(f"   {step.get('icon', '‚Ä¢')} {step.get('step', '')}: {step.get('description', '')[:60]}...")

        # Evaluate with LLM
        print("\nü§ñ LLM Evaluation...")
        evaluation = evaluate_response(test, system_response)

        if "error" in evaluation:
            print(f"‚ùå Eval Error: {evaluation['error']}")
            results.append({"test_id": test.id, "pass": False, "error": evaluation['error']})
            failed += 1
            continue

        # Print evaluation results
        d_score = evaluation.get('detection_score', 0)
        a_score = evaluation.get('action_score', 0)
        r_score = evaluation.get('reasoning_score', 0)
        overall = evaluation.get('overall_score', 0)
        test_passed = evaluation.get('pass', False)

        print(f"\nüìä SCORES:")
        print(f"   Detection:  {d_score}/10 - {evaluation.get('detection_analysis', '')[:50]}...")
        print(f"   Action:     {a_score}/10 - {evaluation.get('action_analysis', '')[:50]}...")
        print(f"   Reasoning:  {r_score}/10 - {evaluation.get('reasoning_analysis', '')[:50]}...")
        print(f"   {'‚îÄ' * 40}")
        print(f"   OVERALL:    {overall}/10")

        if test_passed:
            print(f"\n‚úÖ PASS: {evaluation.get('summary', '')}")
            passed += 1
        else:
            print(f"\n‚ùå FAIL: {evaluation.get('summary', '')}")
            failed += 1

        results.append({
            "test_id": test.id,
            "test_name": test.name,
            "pass": test_passed,
            "scores": {
                "detection": d_score,
                "action": a_score,
                "reasoning": r_score,
                "overall": overall
            },
            "summary": evaluation.get('summary', '')
        })

    # Final Summary
    print("\n" + "=" * 80)
    print("üìà FINAL RESULTS")
    print("=" * 80)
    print(f"‚úÖ Passed: {passed}/{len(TEST_CASES)}")
    print(f"‚ùå Failed: {failed}/{len(TEST_CASES)}")
    print(f"üìä Pass Rate: {(passed/len(TEST_CASES))*100:.1f}%")

    # Average scores
    valid_results = [r for r in results if "scores" in r]
    if valid_results:
        avg_detection = sum(r["scores"]["detection"] for r in valid_results) / len(valid_results)
        avg_action = sum(r["scores"]["action"] for r in valid_results) / len(valid_results)
        avg_reasoning = sum(r["scores"]["reasoning"] for r in valid_results) / len(valid_results)
        avg_overall = sum(r["scores"]["overall"] for r in valid_results) / len(valid_results)

        print(f"\nüìä Average Scores:")
        print(f"   Detection:  {avg_detection:.1f}/10")
        print(f"   Action:     {avg_action:.1f}/10")
        print(f"   Reasoning:  {avg_reasoning:.1f}/10")
        print(f"   Overall:    {avg_overall:.1f}/10")

    # List failures
    failures = [r for r in results if not r.get("pass", False)]
    if failures:
        print(f"\n‚ùå Failed Tests:")
        for f in failures:
            print(f"   ‚Ä¢ Test {f['test_id']}: {f.get('test_name', 'Unknown')} - {f.get('summary', f.get('error', 'Unknown error'))[:60]}")

    return results


if __name__ == "__main__":
    run_tests()
